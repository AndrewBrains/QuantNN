{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "test_larq.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "F3C4o7ClIDJH",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "!pip install larq\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GiyBO0BJcQcT",
        "colab_type": "text"
      },
      "source": [
        "###Full prec model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p2jPKZZNITLk",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import tensorflow as tf\n",
        "import larq as lq\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la5rjHjcIU7z",
        "colab_type": "code",
        "outputId": "bd90af74-b362-4914-d844-03644a67e6ef",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "num_classes = 10\n",
        "\n",
        "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.cifar10.load_data()\n",
        "\n",
        "train_images = train_images.reshape((50000, 32, 32, 3)).astype(\"float32\")\n",
        "test_images = test_images.reshape((10000, 32, 32, 3)).astype(\"float32\")\n",
        "\n",
        "# Normalize pixel values to be between -1 and 1\n",
        "train_images, test_images = train_images / 127.5 - 1, test_images / 127.5 - 1\n",
        "\n",
        "train_labels = tf.keras.utils.to_categorical(train_labels, num_classes)\n",
        "test_labels = tf.keras.utils.to_categorical(test_labels, num_classes)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz\n",
            "170500096/170498071 [==============================] - 6s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V9rV_ihVcP6L",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = tf.keras.models.Sequential([\n",
        "    # In the first layer we only quantize the weights and not the input\n",
        "    tf.keras.layers.Conv2D(128, 3,\n",
        "                          use_bias=False,\n",
        "                          input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    tf.keras.layers.Conv2D(128, 3, padding=\"same\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, 3, padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    tf.keras.layers.Conv2D(256, 3, padding=\"same\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, 3, padding=\"same\"),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    tf.keras.layers.Conv2D(512, 3, padding=\"same\"),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    tf.keras.layers.Dense(1024),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(1024),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Dropout(0.25),\n",
        "    tf.keras.layers.Dense(10),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Activation(\"softmax\")\n",
        "])\n",
        "model.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u6EdZ5kVuGFy",
        "colab_type": "code",
        "outputId": "40861207-8037-48dc-e2f9-00e1d95e8f8c",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Go to this URL in a browser: https://accounts.google.com/o/oauth2/auth?client_id=947318989803-6bn6qk8qdgf4n4g3pfee6491hc0brc4i.apps.googleusercontent.com&redirect_uri=urn%3aietf%3awg%3aoauth%3a2.0%3aoob&response_type=code&scope=email%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdocs.test%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive%20https%3a%2f%2fwww.googleapis.com%2fauth%2fdrive.photos.readonly%20https%3a%2f%2fwww.googleapis.com%2fauth%2fpeopleapi.readonly\n",
            "\n",
            "Enter your authorization code:\n",
            "··········\n",
            "Mounted at /content/gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTIAVw9uuSqZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('/content/gdrive/My Drive/BNN_works/QCIFAR10/DuringTrain/original_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1oGapd_zdNCZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    tf.keras.optimizers.Adam(lr=0.01,decay=0.0001),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4wvZdL7ddQWK",
        "colab_type": "code",
        "outputId": "e4102bf9-3f8b-41f4-e846-7cf751c9aca1",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        }
      },
      "source": [
        "trained_model = model.fit(\n",
        "    train_images, \n",
        "    train_labels,\n",
        "    batch_size=50, \n",
        "    epochs=50,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "1000/1000 [==============================] - 77s 77ms/step - loss: 1.5391 - accuracy: 0.4911 - val_loss: 9.2222 - val_accuracy: 0.3728\n",
            "Epoch 2/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 1.2676 - accuracy: 0.6273 - val_loss: 2.2101 - val_accuracy: 0.5725\n",
            "Epoch 3/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 1.1658 - accuracy: 0.6787 - val_loss: 1.4309 - val_accuracy: 0.6633\n",
            "Epoch 4/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 1.1001 - accuracy: 0.7087 - val_loss: 1.2474 - val_accuracy: 0.6734\n",
            "Epoch 5/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 1.0441 - accuracy: 0.7360 - val_loss: 1.0211 - val_accuracy: 0.6882\n",
            "Epoch 6/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 1.0010 - accuracy: 0.7605 - val_loss: 0.9678 - val_accuracy: 0.6956\n",
            "Epoch 7/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.9528 - accuracy: 0.7828 - val_loss: 0.8166 - val_accuracy: 0.7402\n",
            "Epoch 8/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.9147 - accuracy: 0.8065 - val_loss: 0.7934 - val_accuracy: 0.7549\n",
            "Epoch 9/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.8713 - accuracy: 0.8318 - val_loss: 0.7881 - val_accuracy: 0.7635\n",
            "Epoch 10/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.8287 - accuracy: 0.8555 - val_loss: 0.8035 - val_accuracy: 0.7687\n",
            "Epoch 11/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.7855 - accuracy: 0.8821 - val_loss: 0.7965 - val_accuracy: 0.7822\n",
            "Epoch 12/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.7480 - accuracy: 0.9036 - val_loss: 0.8000 - val_accuracy: 0.7908\n",
            "Epoch 13/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.7083 - accuracy: 0.9259 - val_loss: 0.8515 - val_accuracy: 0.7867\n",
            "Epoch 14/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.6751 - accuracy: 0.9411 - val_loss: 0.8673 - val_accuracy: 0.7905\n",
            "Epoch 15/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.6430 - accuracy: 0.9593 - val_loss: 0.9038 - val_accuracy: 0.7833\n",
            "Epoch 16/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.6155 - accuracy: 0.9693 - val_loss: 0.8900 - val_accuracy: 0.7834\n",
            "Epoch 17/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.5883 - accuracy: 0.9776 - val_loss: 0.9366 - val_accuracy: 0.7863\n",
            "Epoch 18/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.5670 - accuracy: 0.9840 - val_loss: 0.9224 - val_accuracy: 0.7856\n",
            "Epoch 19/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.5453 - accuracy: 0.9876 - val_loss: 0.9381 - val_accuracy: 0.7900\n",
            "Epoch 20/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.5270 - accuracy: 0.9917 - val_loss: 0.9648 - val_accuracy: 0.7820\n",
            "Epoch 21/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.5113 - accuracy: 0.9937 - val_loss: 0.9570 - val_accuracy: 0.7813\n",
            "Epoch 22/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4973 - accuracy: 0.9957 - val_loss: 0.9674 - val_accuracy: 0.7835\n",
            "Epoch 23/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4857 - accuracy: 0.9965 - val_loss: 0.9554 - val_accuracy: 0.7837\n",
            "Epoch 24/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4735 - accuracy: 0.9971 - val_loss: 1.0001 - val_accuracy: 0.7740\n",
            "Epoch 25/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4637 - accuracy: 0.9981 - val_loss: 0.9909 - val_accuracy: 0.7808\n",
            "Epoch 26/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4547 - accuracy: 0.9985 - val_loss: 1.0031 - val_accuracy: 0.7779\n",
            "Epoch 27/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4465 - accuracy: 0.9986 - val_loss: 1.0015 - val_accuracy: 0.7749\n",
            "Epoch 28/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4368 - accuracy: 0.9991 - val_loss: 1.0004 - val_accuracy: 0.7720\n",
            "Epoch 29/50\n",
            "1000/1000 [==============================] - 76s 76ms/step - loss: 0.4329 - accuracy: 0.9991 - val_loss: 1.0186 - val_accuracy: 0.7703\n",
            "Epoch 30/50\n",
            "1000/1000 [==============================] - ETA: 0s - loss: 0.4268 - accuracy: 0.9991"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-6992e90ca697>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m50\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_images\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_labels\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m     \u001b[0mshuffle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m )\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[1;32m    870\u001b[0m               \u001b[0mworkers\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    871\u001b[0m               \u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0muse_multiprocessing\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 872\u001b[0;31m               return_dict=True)\n\u001b[0m\u001b[1;32m    873\u001b[0m           \u001b[0mval_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'val_'\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mval_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitems\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    874\u001b[0m           \u001b[0mepoch_logs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_logs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36m_method_wrapper\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m     64\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_method_wrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_in_multi_worker_mode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 66\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mmethod\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     67\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     68\u001b[0m     \u001b[0;31m# Running inside `run_distribute_coordinator` already.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mevaluate\u001b[0;34m(self, x, y, batch_size, verbose, sample_weight, steps, callbacks, max_queue_size, workers, use_multiprocessing, return_dict)\u001b[0m\n\u001b[1;32m   1079\u001b[0m                 step_num=step):\n\u001b[1;32m   1080\u001b[0m               \u001b[0mcallbacks\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mon_test_batch_begin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m               \u001b[0mtmp_logs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtest_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m               \u001b[0;31m# Catch OutOfRangeError for Datasets of unknown size.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1083\u001b[0m               \u001b[0;31m# This blocks until the batch has finished executing.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    578\u001b[0m         \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    579\u001b[0m     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 580\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    581\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    582\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    616\u001b[0m       \u001b[0;31m# In this case we have not created variables on the first call. So we can\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    617\u001b[0m       \u001b[0;31m# run the first trace but we should fail if variables are created.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 618\u001b[0;31m       \u001b[0mresults\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    619\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_created_variables\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    620\u001b[0m         raise ValueError(\"Creating variables on a non-first call to a function\"\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2418\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2419\u001b[0m       \u001b[0mgraph_function\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2420\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=protected-access\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2421\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2422\u001b[0m   \u001b[0;34m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   1663\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[1;32m   1664\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[0;32m-> 1665\u001b[0;31m         self.captured_inputs)\n\u001b[0m\u001b[1;32m   1666\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1667\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[0;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[1;32m   1744\u001b[0m       \u001b[0;31m# No tape is watching; skip to running the function.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1745\u001b[0m       return self._build_call_outputs(self._inference_function.call(\n\u001b[0;32m-> 1746\u001b[0;31m           ctx, args, cancellation_manager=cancellation_manager))\n\u001b[0m\u001b[1;32m   1747\u001b[0m     forward_backward = self._select_forward_and_backward_functions(\n\u001b[1;32m   1748\u001b[0m         \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36mcall\u001b[0;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[1;32m    596\u001b[0m               \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    597\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mattrs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 598\u001b[0;31m               ctx=ctx)\n\u001b[0m\u001b[1;32m    599\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    600\u001b[0m           outputs = execute.execute_with_cancellation(\n",
            "\u001b[0;32m/usr/local/lib/python3.6/dist-packages/tensorflow/python/eager/execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[0;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mctx\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mensure_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m     tensors = pywrap_tfe.TFE_Py_Execute(ctx._handle, device_name, op_name,\n\u001b[0;32m---> 60\u001b[0;31m                                         inputs, attrs, num_outputs)\n\u001b[0m\u001b[1;32m     61\u001b[0m   \u001b[0;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ILxGd2ye5vrR",
        "colab_type": "text"
      },
      "source": [
        "###1 - bit model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R8gNSoB1IXQw",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# All quantized layers except the first will use the same options\n",
        "kwargs = dict(input_quantizer=\"ste_sign\",\n",
        "              kernel_quantizer=\"ste_sign\",\n",
        "              kernel_constraint=\"weight_clip\",\n",
        "              use_bias=False)\n",
        "\n",
        "model = tf.keras.models.Sequential([\n",
        "    # In the first layer we only quantize the weights and not the input\n",
        "    lq.layers.QuantConv2D(128, 3,\n",
        "                          kernel_quantizer=\"ste_sign\",\n",
        "                          kernel_constraint=\"weight_clip\",\n",
        "                          use_bias=False,\n",
        "                          input_shape=(32, 32, 3)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(128, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(256, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(256, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(512, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantConv2D(512, 3, padding=\"same\", **kwargs),\n",
        "    tf.keras.layers.MaxPool2D(pool_size=(2, 2), strides=(2, 2)),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Flatten(),\n",
        "\n",
        "    lq.layers.QuantDense(1024, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantDense(1024, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "\n",
        "    lq.layers.QuantDense(10, **kwargs),\n",
        "    tf.keras.layers.BatchNormalization(momentum=0.999, scale=False),\n",
        "    tf.keras.layers.Activation(\"softmax\")\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4FMPEypYFdXZ",
        "colab_type": "code",
        "outputId": "c9ba5d6b-0efd-4f2c-b9c5-9770e6830eaa",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 714
        }
      },
      "source": [
        "lq.models.summary(model)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "+sequential_1 stats--------------------------------------------------------------------------------------------+\n",
            "| Layer                   Input prec.            Outputs   # 1-bit  # 32-bit   Memory  1-bit MACs  32-bit MACs |\n",
            "|                               (bit)                          x 1       x 1     (kB)                          |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "| quant_conv2d                      -  (-1, 30, 30, 128)      3456         0     0.42           0      3110400 |\n",
            "| batch_normalization_9             -  (-1, 30, 30, 128)         0       256     1.00           0            0 |\n",
            "| quant_conv2d_1                    1  (-1, 30, 30, 128)    147456         0    18.00   132710400            0 |\n",
            "| max_pooling2d_3                   -  (-1, 15, 15, 128)         0         0        0           0            0 |\n",
            "| batch_normalization_10            -  (-1, 15, 15, 128)         0       256     1.00           0            0 |\n",
            "| quant_conv2d_2                    1  (-1, 15, 15, 256)    294912         0    36.00    66355200            0 |\n",
            "| batch_normalization_11            -  (-1, 15, 15, 256)         0       512     2.00           0            0 |\n",
            "| quant_conv2d_3                    1  (-1, 15, 15, 256)    589824         0    72.00   132710400            0 |\n",
            "| max_pooling2d_4                   -    (-1, 7, 7, 256)         0         0        0           0            0 |\n",
            "| batch_normalization_12            -    (-1, 7, 7, 256)         0       512     2.00           0            0 |\n",
            "| quant_conv2d_4                    1    (-1, 7, 7, 512)   1179648         0   144.00    57802752            0 |\n",
            "| batch_normalization_13            -    (-1, 7, 7, 512)         0      1024     4.00           0            0 |\n",
            "| quant_conv2d_5                    1    (-1, 7, 7, 512)   2359296         0   288.00   115605504            0 |\n",
            "| max_pooling2d_5                   -    (-1, 3, 3, 512)         0         0        0           0            0 |\n",
            "| batch_normalization_14            -    (-1, 3, 3, 512)         0      1024     4.00           0            0 |\n",
            "| flatten_1                         -         (-1, 4608)         0         0        0           0            0 |\n",
            "| quant_dense                       1         (-1, 1024)   4718592         0   576.00     4718592            0 |\n",
            "| batch_normalization_15            -         (-1, 1024)         0      2048     8.00           0            0 |\n",
            "| quant_dense_1                     1         (-1, 1024)   1048576         0   128.00     1048576            0 |\n",
            "| batch_normalization_16            -         (-1, 1024)         0      2048     8.00           0            0 |\n",
            "| quant_dense_2                     1           (-1, 10)     10240         0     1.25       10240            0 |\n",
            "| batch_normalization_17            -           (-1, 10)         0        20     0.08           0            0 |\n",
            "| activation_1                      -           (-1, 10)         0         0        0           ?            ? |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "| Total                                                   10352000      7700  1293.75   510961664      3110400 |\n",
            "+--------------------------------------------------------------------------------------------------------------+\n",
            "+sequential_1 summary-------------------------+\n",
            "| Total params                      10.4 M    |\n",
            "| Trainable params                  10.4 M    |\n",
            "| Non-trainable params              7.7 k     |\n",
            "| Model size                        1.26 MiB  |\n",
            "| Model size (8-bit FP weights)     1.24 MiB  |\n",
            "| Float-32 Equivalent               39.52 MiB |\n",
            "| Compression Ratio of Memory       0.03      |\n",
            "| Number of MACs                    514 M     |\n",
            "| Ratio of MACs that are binarized  0.9939    |\n",
            "+---------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QeRF-jxZxklr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.save_weights('/content/gdrive/My Drive/BNN_works/QCIFAR10/DuringTrain/original_model_weights.h5')"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bJTVh924Ivb7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model.compile(\n",
        "    tf.keras.optimizers.Adam(lr=0.01,decay=0.00003),\n",
        "    loss=\"categorical_crossentropy\",\n",
        "    metrics=[\"accuracy\"],\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ENCGxIm9I1B1",
        "colab_type": "code",
        "outputId": "ae32021b-8b4d-4f10-c8ec-f7a67edd33e0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        }
      },
      "source": [
        "trained_model = model.fit(\n",
        "    train_images, \n",
        "    train_labels,\n",
        "    batch_size=50, \n",
        "    epochs=100,\n",
        "    validation_data=(test_images, test_labels),\n",
        "    shuffle=True\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "1000/1000 [==============================] - 83s 83ms/step - loss: 1.5718 - accuracy: 0.4554 - val_loss: 1.7980 - val_accuracy: 0.3821\n",
            "Epoch 2/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 1.1488 - accuracy: 0.6383 - val_loss: 2.0229 - val_accuracy: 0.2790\n",
            "Epoch 3/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.9664 - accuracy: 0.7193 - val_loss: 1.7391 - val_accuracy: 0.4211\n",
            "Epoch 4/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.8446 - accuracy: 0.7716 - val_loss: 1.4138 - val_accuracy: 0.5339\n",
            "Epoch 5/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.7606 - accuracy: 0.8098 - val_loss: 1.3620 - val_accuracy: 0.5853\n",
            "Epoch 6/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.6997 - accuracy: 0.8396 - val_loss: 1.2105 - val_accuracy: 0.6287\n",
            "Epoch 7/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.6486 - accuracy: 0.8625 - val_loss: 0.9393 - val_accuracy: 0.7422\n",
            "Epoch 8/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.6085 - accuracy: 0.8823 - val_loss: 0.9442 - val_accuracy: 0.7446\n",
            "Epoch 9/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.5758 - accuracy: 0.8987 - val_loss: 1.0799 - val_accuracy: 0.6886\n",
            "Epoch 10/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.5499 - accuracy: 0.9100 - val_loss: 0.9712 - val_accuracy: 0.7349\n",
            "Epoch 11/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.5275 - accuracy: 0.9212 - val_loss: 0.8969 - val_accuracy: 0.7719\n",
            "Epoch 12/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.5122 - accuracy: 0.9293 - val_loss: 0.9476 - val_accuracy: 0.7482\n",
            "Epoch 13/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4992 - accuracy: 0.9352 - val_loss: 0.8519 - val_accuracy: 0.7845\n",
            "Epoch 14/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4930 - accuracy: 0.9402 - val_loss: 0.9464 - val_accuracy: 0.7638\n",
            "Epoch 15/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4816 - accuracy: 0.9444 - val_loss: 0.8957 - val_accuracy: 0.7780\n",
            "Epoch 16/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4780 - accuracy: 0.9473 - val_loss: 0.9312 - val_accuracy: 0.7557\n",
            "Epoch 17/100\n",
            "1000/1000 [==============================] - 82s 82ms/step - loss: 0.4706 - accuracy: 0.9520 - val_loss: 0.9474 - val_accuracy: 0.7592\n",
            "Epoch 18/100\n",
            " 158/1000 [===>..........................] - ETA: 1:04 - loss: 0.4561 - accuracy: 0.9572"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}